


library(dplyr)
library(data.table)
library(skimr)
library(tidyverse)
library(janitor) 


# read and load csv
data <- fread("mini_task.csv")


# all columns are read as factor (not chr) for accuracy
head(data)


# Initial Exploration and Cleaning with janitor
data %>% 
  tabyl(`Adaptivity Level`)
data %>% 
  tabyl(`Financial Condition`)
data %>% 
  tabyl(`Internet Type`)
data %>% 
  tabyl(`Network Type`)
data %>% 
  tabyl(`Device`)
data %>% 
  tabyl(`Age`)
data <- data %>% 
  clean_names() # Clean column names (replace spaces with underscores, etc.)


# Age Cleaning
data <- data %>%
  mutate(age_numeric = case_when(
    age == "1-5" ~ 3,
    age == "6-10" ~ 8,
    age == "11-15" ~ 13,
    age == "16-20" ~ 18,
    age == "21-25" ~ 23,
    age == "26-30" ~ 28,
    TRUE ~ NA_integer_
  )) %>%
  select(-age)


# Convert to factors (crucial for Shiny and analysis)
data <- data %>%
  mutate(
    gender = as.factor(gender),
    education_level = as.factor(education_level),
    institution_type = as.factor(institution_type),
    it_student = as.factor(it_student),
    location = as.factor(location),
    load_shedding = as.factor(load_shedding),
    financial_condition = as.factor(financial_condition),
    internet_type = as.factor(internet_type),
    network_type = as.factor(network_type),
    class_duration = as.factor(class_duration),
    self_lms = as.factor(self_lms),
    device = as.factor(device),
    adaptivity_level = factor(adaptivity_level, levels = c("Low", "Moderate", "High"), ordered = TRUE)
  )


# check data dimensions; Check the data dimensions (number of rows and columns)
dim(data)


# Check the column names to get column names
colnames(data)


# Check the bottom of data to see the last observations
tail(data)


# Check for missing values in each column
colSums(is.na(data))


# My interpretation for this type of data is not true duplicates. Though there are redundancy and rows has no unique keys
# For this reason duplicates won't be drop
duplicates <- duplicated(data)
sum(duplicates)


# Create a new data frame without any duplicate rows
# data <- unique(data)


# count remaining rows
num_unique_rows <- nrow(df)
print(num_unique_rows)


naniar::gg_miss_var(data)  # Missing variables





# EDA for Equity Analysis
# Example: Adaptability vs. Financial Condition
data %>%
  ggplot(aes(x = financial_condition, fill = adaptivity_level)) +
  geom_bar(position = "fill") +
  labs(title = "Adaptability Level by Financial Condition",
       x = "Financial Condition",
       y = "Proportion of Students")



write.csv(data, "cleaned_data.csv")


str(data)


dim(data)


# Outliers detection using Z-scores
values <- data$age_numeric
mean_value <- mean(values, na.rm = TRUE)
sd_value <- sd(values, na.rm = TRUE)
z_scores <- (values - mean_value) / sd_value
outliers <- values[abs(z_scores) > 3]
print(outliers)
